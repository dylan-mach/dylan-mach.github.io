---
title: "Urbhealth: Connecting Urban Planning and Community Health"
author: "Dylan Mach, Andrew Mitchell"
format:
  html:
    embed-resources: true
    toc: true
    code-tools: true
    code-fold: true
editor: visual
mainfont: Baskerville
monofont: JetBrainsMono-Light
---

# Introduction

With the advance of widely accessible public health and urban design datasets, people have even greater access to data from the general public, making large datasets detailing certain community health metrics open to the world . However, this data is often not easily accessible, making it quite difficult to peruse the millions of dataset provided by the government to figure out what exactly has caused a significant portion of the community's health outcomes. Through this project, this data will be searched, parsed, and analysed through regression analysis and an average health metric index algorithm to give us a greater insight into what health metrics are the most significant in terms of community health outcomes.

## Urban Health Indicators Use

Global urbanisation has been linked to increasing health problems in urban communities around the world, recognising the need for accurate and careful urban planning policy-making corburn_why_2012. In order to tie decision-making to accurate prioritisation of urban areas, especially on a localised scale, urban health indicators (UHIs) have often been used. UHIs are defined as tools that contribute to decision-making through quantitative representation of health inequalities and conditions in urban environments. Formally, a UHI is “a collection of summary measures about the physical urban environment’s contribution to human health and wellbeing”, which usually serves the purpose of depicting a "complex social, economic or physical reality" mullin_measuring_nodate. Measures typically relate to "quality of life, liveability, and wellbeing". UHIs often serve multiple purposes in decision-making processes, including informing urban citizens, marking potential problems, and allowing for reasoned prioritisation. For example, the San Francisco Department of Public Health guides decision-making concerning land use and development, where a combination of government agencies and informed citizens developed optimal future plans for the city. Additionally, UHIs were utilized in Bristol, UK that effectively informed citizens and provided transparency and priorities for future city work. Various individual indicators contribute to a UHI — these indicators are typically certain patterns in urban planning seen to have significant correlation with health outcomes. Thus, we also make a distinction between UHIs and individual indicators — UHIs are quantitative representations of a broader concept, and are made up of individual indicators.

\

## Indicator Patterns

Numerous urban measures used in indicators have established correlations with public health outcomes. The amount of green space in urban areas has been linked to improved mental health and encouraged more physical activity, while also decreasing community violence and death rate. Implementation of supermarkets (sources of fresh food) has accompanied lower food insecurity rates, lower dependence on federal food aid, and improved overall well-being health-wise. Widespread community accessibility to public transport has been linked to lower rates of obesity, decreased pollutant and emission concentrations, and lowered other prominent cardiovascular and mental health ailments (Litman, 2016). While these indicators can have strong correlations with health outcomes, causality cannot be attributed to them, as these studies are observational and cannot establish causality. However, these studies highlight measured relationships between urban planning and public health that can be communicated and utilised to foster prioritised decision-making. Additionally, these are commonly utilized indicators in UHI development due to their ability to be measured, widespread availability of data, and accurate depictions of public health. It is also important to avoid considering these indicators to have direct impact on health outcomes, as indicators influence a variety of factors that contribute to health outcomes. 

A purpose of many existing UHIs in literature is to simplify decision-making in a complex field (urban planning and its ties to public health), causing decisions to be streamlined and efficient. This simplification occurs by representing relationships and correlations as numerical values. However, in order to do so successfully, UHIs must logically account for complexities in the field; many UHIs did not explicitly mention a methodology to do so. Additionally, indicator selection for current UHIs appears to be influenced by the difficulty of obtaining such indicators, making data that is easier to measure and analyze more likely to contribute to UHIs. 

## Indicator Development - Methodologies

While many UHIs have been produced in the past, methodologies often vary. Some indices centre around the summation of separate, constituent scores that are calculated on their own basis, usually as a standardised statistic higgs_urban_2019. This index methodology is present in the Urban Liveability Index (ULI), where various statistical measures, including density measures, ratios, and ordinal measures, were calculated independently, standardised to allow for equal and valid comparison, and summated. Indices similar to the Child Opportunity Index focus solely on standardisation, in which z-score positions across a wide array of indicators constitute a singular, combined index score acevedo-garcia_child_2014. Indices that are constructed with subjective data, including the Community Well-Being Index (A) in Korea, also utilise standardisation and z-score methodologies by quantifying opinions through psychometric scales like the Likert scale kim_development_2014. Polynomial estimation, especially at higher degrees, can also predict behaviours of certain indicators. For example, the HealthyCity Air-Noise Index utilises a third-degree polynomial to estimate noise annoyance, a formulated yet accurate method to quantify a subjective indicator silva_environmental_2015. 

Many indices take a more differentiated path where specific weights modify existing data, making certain indicators have a stronger contribution on the final index score than other indicators. A common pathway of weighting indicators is Data Envelopment Analysis (DEA), which generally examines efficiency in how well an input/independent variable stimulates an output/dependent variable, especially in the context of many inputs and outputs. The Subjective Community Well-Being Indicator uses this approach, where social and financial aspects (e.g. health, job opportunities) are analysed against satisfaction in various corresponding fields bernini_dea-like_2013. Additionally, weights can be arbitrarily generated in sets, where each set undergoes sensitivity analysis to determine if it optimally formulates the UHI rothenberg_flexible_2014. Generating various iterations of weight sets is recommended for arbitrary weighting; Rothenburg et al.’s UHI uses n = 1000 sets, each undergoing sensitivity analysis. 

Sometimes, weights are simply chosen on a relativistic scale, which is most often based on perceived significance and data reliability. Yale’s Environmental Performance Index subjectively perceives different indicators and their relationships with environmental status and policy, as well as weighing in data reliability (Block, 2024). For instance, weights are decreased for an indicator that has only one year of data or rendered more obsolete compared to other indicators with respect to its impacts on a certain outcome. Weights can also be attributed to statistical measures, which analyze indicator purpose to a more pure, objective lens. The Human Development/Poverty Indices in India determines weights through factor loadings, a measure of correlation between indicators and the outcome sourcing from SPSS analysis (Antony, 2007). This increases the significance of indicators that are more closely related to health outcomes compared to indicators that aren’t.

A more unique yet solid indicator construction technique is the Mazziato-Pareto Index (MPI) technique, which uses an arithmetic mean modulated by a penalizing factor. An arithmetic mean allows for non-arbitrary index determination, while the penalty adjustment (derived from indicator variability) prevents high indicator values from overshadowing low indicator values. Another technique is the Alkire-Foster (AF) method, which multiplies incidence by intensity (UNDP, 2023). Indicators are portrayed as binary, with specific hard thresholds marking whether or not the indicator contributes or does not contribute to the incidence. For example, in the Multidimensional Poverty Index, the poverty rate threshold is set such that only areas above that threshold would count - there is no soft gradient. Incidence is also determined by a hard threshold. Incidence is a proportion of areas that have a certain amount of indicators above their respective thresholds. Intensity is the average number of indicators above thresholds among areas that count toward incidence. The AF method provides a holistic viewpoint of not only where areas are affected, but how broader areas of studies are faring. 

Other studies acknowledge the potential limitations on weighting indicators (especially differentially), citing that unequal weighting often resulted in rigid analysis across geographical areas with different trends and the faulty association of low correlation evidence with low influence. (Pineo, 2017). The practice of equating weights to certain statistical values (e.g. R2) can seem objective but masks temporal trends and socioeconomic trends with statistical values, which could incorrectly skew interpretations of data and compromise index integrity. Additionally, weighting loses some effectiveness when multiple outcomes are in play (i.e. multiple health diseases are studied), as a unique set of weights must be developed for each individual outcome richardson_developing_2010.

Regardless, most UHI development methodologies involve a filtration process to determine a concise, representative set of urban indicators to explain health trends (Pineo, 2018). Indicator filtration typically includes considerations of data availability, data recency, and clear purposes of data measurement (to avoid ambiguity in future interpretation). After a set of indicators is selected, weights are assigned to indicators in order to differentiate levels of impact on health outcomes (although weights can also be set equal to avoid limitations). Data values for each indicator are used in correspondence with their weights to create individual indicator values for each geographic area. (Pineo, 2017)

# Methods

We first selected an optimal geographic scale (based on a territorial division). Scale is important to prevent sweeping over-generalisations (from a broader scale) or cases of overfitting (from a narrower scale). This indicated that ZIP codes, census tracts, or census blocks would be the most optimal scale of analysis. ZIP codes were ultimately rejected for the scale of analysis because they centre around mailing statistics, which could poorly explain demographic trends. Census blocks were not chosen because of high chances of overfitting and the lack of data accessibility (for both urban indicators and public health statistics). 

To initialize analysis, we browsed through a set of X distinct urban indicators. This set was chosen on both objective and subjective criteria; while they must be measurable and accessible across all geographical areas (and on the census tract basis), they must also have a logical connection to public health, potentially eliminating possibilities of relationships produced by random chance. After this first analysis, seven indicators remained.

## Data Processing

We subjectively selected response datasets under two main criteria: 1) They were common diseases in urban areas and 2) Their frequencies did not have high amounts of genetic influence (although some genetic influence is unavoidable). This criteria was selected in order to prevent unnecessary analysis on diseases that were not impacted or related to aspects of urban planning. 

Because a wide array of explanatory variables could contribute to index development, we did not consider a rigid set of criteria for explanatory variable selection. Thus, explanatory variables were selected if they were related to urban planning and could have a logical connection to public health. Additionally, variables must be selected appropriately to prevent overfitting to a large set of variables. A total of 11 explanatory variables were initially selected for use. We obtained data in CSV format and integrated them through Microsoft Excel, where all data points were merged on a common census tract ID. Data plotting, however, indicated large groups of missing data, which sourced from the lack of CDC PLACES data from Florida. Any tracts with the "FL" Census denotation were removed from analysis. Additionally, while most variables had reasonable amounts of missing data, lakids1share (insert description), lahunv1share (insert description), and lapop1share (insert description) had great amounts of missing data, with around 40 percent of data missing for each variables. Any form of substitution for these missing data points would be greatly inaccurate as substitutions would be based on a small proportion of the sample size - therefore, these variables were also included from analysis. 

Additionally, further data plotting indicated large groups of data points that contained "0", especially for the est_ptrp, ht_ami, and est_vmiles variables. These variables are not suitable to be zero because miles travelled daily, vehicular trips daily, and the proportion of income spent on transportation and housing are not plausible to be zero in a census tract demographic. Because the frequency of zeroed values was not in great proportions, we replaced them with NaN values to be later imputed in a process described in detail below. 

Additionally, to objectively center the analysis around urban areas, only urban and suburban tracts were selected. Rural tracts were eliminated based on a tract index derived from population and population density, which was established by the United States Department of Transportation’s Urbanicity Index (BTS, 2024). Rural tracts were identified as tracts that were not Urban Areas (UAs, over 50,000 people) or Urban Centers (UCs, between 2,500 and 50,000 people), meaning that they contained less than 2,500 people. This round of data filtration was also performed in Excel and resulted, alongside with imputation of NaN values, in 47092 census tracts across the nation. Additionally, through a triangular correlation matrix, indicators that shared major multicollinearity problems with other indicators (R2 \> 0.90) were eliminated.

The final set of nine urban indicators allowed for different indicator permutations to be present in all 50 states of the United States. Permutations were chosen based on numerical values of each indicator’s respective variation inflation factor (VIF), which quantified multicollinearity between all chosen indicators in each state. If the maximum VIF value in the set of indicators was above 5, that indicator was removed. Indicators were removed one at a time because the removal of indicators results in lowered VIF scores for all other indicators, as there is less multicollinearity present in the set.

The response dataset was formed by six unique health factors: high blood pressure (BPHigh), high cholesterol (HighChol), coronary heart disease (CHD), chronic obstructive pulmonary disease (COPD), depression, and diabetes. 

Data was collected on the census-tract scale, all from the year 2019 (data collected decenially were from 2010 instead of 2020 to avoid COVID-19 complications in the data).

## Data Description

Explanatory datasets were sourced from the National Neighborhood Data Archive at the University of Michigan (NaNDA), the US Census Bureau, the United States Department of Agriculture (USDA) Food Access Research Atlas, the United States Bureau of Transportation Statistics Local Area Transportation Characteristics for Households (LATCH), the Housing and Transportation Affordability Index (H+T), and the University of Minnesota's Access Across America. NaNDA provided data on tract proportions of public transportation stops (stops) and park areas (park_area). The US Census Bureau provided a common thread of identification data between datasets, including state and population. The USDA Food Access Research Atlas provided data about food insecurity, measuring the proportion of a tract who had low access to food in a 0.5-mile radius (halfshare), as well as the percentage of families in a tract with low/no access to private vehicles (hunv). The LATCH provided data on vehicular usage, primarily in the form of person-trips (ptrp), the number of trips by one person in any form of transport in a day, or vehicle-miles (vmiles), the number of miles driven by a vehicle in a day multiplied by the passenger quantity. H+T provided data on employee gravity (emp_gravity), the total number of jobs in a tract divided by the square of its distance from the tract centroid, and the annual income spent on transportation and housing (ht_ami). Data from the Access Across America dataset related to job accessibility with respect to transit (transit), which measures the number of accessible jobs a person can reach through public transit services within an 1800-second threshold (a subjective selection that represents a tolerable commute time for an average worker). 

Response datasets (health outcomes) were sourced from PLACES (Local Data for Better Health, Place Data 2020 release) by the Centers of Disease Control and Prevention. This 2020 PLACES release specifically contained model-based places, which include counties, places, census tracts, and ZIP Code tabulation Areas. PLACES data initially sourced from survey data, which are later analyzed in multilevel logistic regression models (CDC, 2022). That regression, which takes into account age, sex, race, education, and poverty rates, is responsible for estimating all six of the health metrics used in this paper. It is important to note that PLACES failed to tabulate data from Florida due to insufficient data tracking, causing this analysis to exclude Florida (CDC, 2022). In addition, it is also important to note that covariates are already accounted for within the production of the PLACES dataset. Therefore, it is unnecessary to control for demographic characteristics like age or sex when utilizing the PLACES dataset (Kong, 2020). 

To develop a regression model, Python was utilised to create a program that takes a certain number of metrics and compares them to determine the statistical significance of proportionality and means between variables. Then, semi-partial correlation was utilised to find individual Pearson r-values that would eliminate covariate influence on the analysis. This variable analysis led to the development of the Urbhealth index.

### Person-trips

The measure of person-trips was abbreviated to be `ptrp` throughout this analysis. A person-trip is defined by the United States Bureau of Transportation Statistics Local Area Transportation Characteristics for Households Survey (LATCH) as a trip made by a person in any mode of transportation -- trips are generally subdivided into the categories of personal errands, social, work, church/school, work-related-business, and other. We utilized the LATCH dataset that was produced in 2017.

### Vehicle-miles

The measure of vehicle-miles was abbreviated to be `est_vmiles` throughout this analysis. A vehicle-mile is defined by the United States Bureau of Transportation Statistics LATCH Survey to be one vehicle traveling one mile. This means that this dataset is passenger-independent, as more than one passenger can ride in the same vehicle. (However, adjustments for trains and other multi-car modes of transportation are included.) We utilized the LATCH dataset that was produced in 2017.

### Parks by Census Tract

The measure of the proportion of a census tract's area that is designated to be a park was abbreviated to be `ParkAreaProportion`. This measure is produced by the National Neighborhood Data Archive (NaNDA) at the University of Michigan. This dataset utilized the census TIGER/Line shapefiles (2010) to accurately delineate census tract boundaries and, through ArcGIS, utilized a pairwise intersect to merge enclosed areas from those shapefiles and the ParkServe shapefiles, which provided geospatial data on parks. Then, area inside of enclosed areas that also include parks from the ParkServe shapefiles were used to calculate the proportion of parks per census tract (as a percentage) utilized in this analysis. We utilized the NaNDA dataset that was produced in 2018.

### Public Transit Stops by Census Tract

The measure of the amount of public transit stops within a census tract was abbreviated as `StopsperSqMile` throughout this analysis and was also sourced from NaNDA. Census tract delineation for this dataset utilized the TIGER/Line Shapefiles (2010), and data for the public transport stops was sourced from the National Transit Map (NTM). This data allowed for sufficient information to derive the count and density of transit stops within a census tract. We utilized the NaNDA dataset that covered the years between 2016 and 2018.

### Housing and Transportation Area Median Income

The measure of Housing and Transportation Area Median Income was abbreviated to `ht_ami` throughout this analysis. ht_ami is calculated to be the percentage of the income for the regional typical household (which is also the area median income) that is attributed to both housing and transportation costs. This calculation derives from the H+T Affordability Index. A regional typical household is defined to be a household income that is calculated as the median of the region. Additionally, for these households, regional average household size and commuters per household values are utilized. We utilized the dataset produced in 2022, which relies on 2019 data for its production.

### Employee Gravity

The measure of employee gravity was abbreviated to `empgravity` throughout this analysis. Employee gravity is defined by the H+T Affordability Index as the total number of jobs in a tract divided by the square of its distance from the tract centroid. The tract centroid is the approximate geographic center of the geospatial census tract polygon. We utilized the dataset produced in 2022, which relies on 2019 data for its production.

### Noise Exposure

The measure of noise exposure was specifically chosen to represent the population-weighted noise exposure, and is abbreviated `nsaverage` throughout the analysis. We utilized a formula to manually calculate the population-weighted noise exposure from the National Transportation Noise Exposure dataset provided by the University of Washington Deohs School of Public Health. This formula, instead of using specific decibel ranges of noise exposure, provides a single metric for each census tract by combining a weighted average of all of the decibel ranges. We utilized the dataset that was produced within a 2023 paper.

## Initial data scaling and processing

To begin data analysis, a level of territorial division had to be selected uniformly across the US. While states, counties, and city limits were too general and would not allow analysis of individual neighborhood and urban areas, census blocks were too specific and would provide overfitted data. Census tracts were chosen over ZIP codes because ZIP codes center around mailing and delivery statistics, making them a more inaccurate marker of demographic trends.

The initial sample size comprised all census tracts in the United States. However, because this study centres around urban planning, not all census tracts need to be studied. A dataset was utilized to determine if census tracks were urban, suburban, or rural based on their respective population densities. Since urban planning effects on rural areas are negligible, they were removed from the study. This did not significantly impact the sample size, as the census tract count remained over 40,000.

To finalise the datasets, multiple explanatory variables (e.g. public transportation frequency, park area, etc.) and response variables (e.g. Chronic obstructive pulmonary disease (COPD), obesity, etc.) that were tied to urban policy were explored. Statistics for these variables were found on the census-tract scale and aggregated from a singular dataset that housed all census tracts and their respective demographic data. Additionally, statistics were segregated based on their population density within the respective parameters shown in \\creftab:base-stats.

## Feature Selection 

At this stage, we had a finalized set of eight individual urban indicators and six health factors, which were all cleaned and imputed as mentioned in the Data Processing section. However, in order to further proceed into model development, we determined a methodology to filter the indicator subset to reduce computational strain and prevent overfitting. A standard correlation matrix was rejected to detect good fit because of a future objective to construct a non-linear model -- correlation matrices typically use ordinary least squares (OLS) regression, which is a linear process. Thus, we picked mutual information to select indicators. Mutual information can be defined as how much information on one variable is given by another variable.

We computed the mutual information values in R by using the `condinformation` function from the `infotheo` library. By setting up a nested for loop to cycle through both indicator and health factor subsets, we compute all permutations of mutual information, and can consolidate those data points into a matrix as shown below:

Two variables had noticeably higher mutual information (MI) values than the others: est_vmiles and est_ptrp. This makes sense for several reasons. Since those two variables are inherently related (but not related enough to have a high multicollinearity, as seen in the original multicollinearity analysis), they should share consistent results. Also, health outcomes come in similar frequencies, especially since many can be related. Additionally, we noted that graphing a line graph for mutual information values from high to low would form a shape resembling exponential decay, which indicates that the majority of indicators would not have high mutual information values -- that is, only a few indicators highly influence dependent variable behaviour.

We also noted that there were no standard thresholds for mutual information values in studied scientific literature: "In general, it is not straightforward to develop guidelines for cut-offs of MI indicating weak or strong relationships" (Young, 2023). The only indication of relative mutual information is when MI values are zero, which indicates the absence of relationships between the analysed independent variable and dependent variable. Therefore, we could not create a substantiated threshold for reference. Thus, we determined that the majority of dependent variable information can be explained, on the line graph, by the variables with MI values above the sharpest bend of the graph. This can be determined by inspection. 

However, solving for MI values only rejects any variability in mutual information between states, as we consider states as a hierarchical variable later. Thus, we must use conditional information, where we can calculate the amount of information that one variable provides over the other when we are given a fixed value for a third variable; in this situation, the third variable is the state. By running a similar function in R with calculating MI values, except adding a function to condition on the "States" variable, we produced the following conditional mutual information (CMI) matrix:

Here, we also notice similar patterns to the MI value matrix, where the variables est_vmiles and est_ptrp are able to explain the most information for each health disease factor. We deemed this result to be reasonable as conditioning on the state should not heavily alter the amount of information explained.

## Model and Parameter Selection

The model that we chose to calculate our UHI, Urbhealth, was a hierarchical generalised additive model. First, we wanted to select a model that represented non-linear trends, which allows for non-linear relationships in data to be explored. Therefore, we selected an HGAM, which allowed us to form a custom polynomial as a summation of multiple non-linear functions for the individual indicators. A hierarchical version of a generalised additive model (GAM) was selected in order to establish hierarchies by state. We chose to establish these state hierarchies to produce a single common smoother among every model. in addition to state smoothers that have equal wiggliness. We selected this HGAM methodology to acknowledge that states should have similar template model shapes (as there are no drastic differences in disease frequencies across the United States); however, we also allowed for state-level smoothers to incorporate smaller variations in model shapes that could differentiate across states.

Since all variables studied are considered continuous (except the State variable, which when quantitatively indexed, is discrete), it is appropriate to represent all of the individual indicators as smooth functions, by the s() function in the "mgcv" library in R. Smooth functions were assigned to each urban indicator with the default bs = "tp" function, which produces thin plate splines (TPS). We selected TPSs as a model because they are "ideal for examining the combined effect of two continuous predictors on a single outcome", which facilitated modelling between multiple urban indicators and individual health factors. 

In order to factor in the State variable in the model, which is a discrete variable when indexed, we utilized the factor smooth ("fs") model parameter within the mgcv library, where bs = "fs". This model parameter was a modification of the proposed HGAM model parameters established by Pederson in the context of a global smoothing parameter that creates generalised shape while also accounting for geographic heterogeneity through smaller, adjusting smoothing terms for individual state groups (Pederson, 2019), which aligns with our goals of model construction stated in the above paragraphs in this section. 

Multicollinearity, or significant evidence of correlation between multiple explored independent variables, was investigated by observing concurvity, a non-linear analogue to the variance inflation factor (VIF). We deemed it improper to use multicollinearity analysis for the HGAM model because multicollinearity observes overlapping linear trends, while this model utilized non-linear trends. This increases the chance of false multicollinearity analysis values that do not accurately reflect on the model shape; utilizing concurvity accommodates for that issue. Concurivty produces three separate analyses estimates by examining a ratio of a decomposed basis model `g` to the original smooth model `f` if `g` consists of the basis functions of all other variablex except the one analysed. Although there is no prevalent established threshold for model quality based on concurvity value, some sources indicate a threshold of 0.5 or lower indicates a viable model with low non-linear multicollinearity (Ramsay, 2003). Although the concurvity function produces three separate analyses, the "estimated" analysis was used for accurate model analysis, while the "worst" analysis was used for a rough benchmark of model performance. 

Statistical significance in this project was analysed within the scholarly social sciences parameters, in which a standard R\^2 between 0.10 and 0.50 is acceptable as long as each explanatory variables is significant relative to the response variable (p \< 0.05). 

Most states were not placed in clusters in order to maximize homogeneity in samples. However, ones that had low population/amount of census tracts were placed in geographic clusters.

# Results

-   Descriptive statistics

-   Model images

-   R2, p-values, significance of smooth terms

-   Discussion of FREML values

```{r setup, include=FALSE}
# knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(kableExtra)
library(tidyverse)
library(readxl)
library(mgcv)
library(MASS)
library(gratia)
library(infotheo)
library(reshape2)
library(ggplot2)
library(car)
library(DT)
library(oddsratio)
library(gtsummary)
library(sjPlot)
library(rlang)
```

## Descriptive Statistics

Table 1 displays the descriptive statistics for the data utilized in this statistical analysis. There were a total of 39,344 census tract samples that were utilized in this analysis. All disease statistics are reported in decimal proportions. Units for other data points are described in the Data Description section.

```{r info}
#| results: asis
#| warning: false
dvs <- c('CHD', 'Depression', 'COPD', 'DIABETES', 'HIGHCHOL', 'BPHIGH', 'Obesity')

data <- read_excel("/Users/dmach/Downloads/clean.xlsx") # non-cleaned data

#rename(data, PAProp = "ParkAreaProportion", StopsSqMile = "StopsperSqMile")

ivs <- c('ParkAreaProportion', 'StopsperSqMile', 'est_vmiles', 'est_ptrp', 'ht_ami', 'emp_gravity', 'nsaverage')

data <- data |> 
    dplyr::select(!starts_with("Unnamed")) |> # remove extra columns
    filter(State != "FL") |> # remove Florida data
    filter(emp_gravity < 300000) # remove emp_gravity single outlier

data$est_ptrp <- na_if(data$est_ptrp, 0) # replace 0 with NA
data$ht_ami <- na_if(data$ht_ami, 0)
data$TractID <- factor(data$TractID) # convert to factor variable
data$State <- factor(data$State)

data[dvs] <- data[dvs] / 100 # convert to percentage 0-1

data <- drop_na(data) # drop missing data

# knitr::kable(summary(data), format = "pipe")
table1 <-
  data |>
  tbl_summary(
    statistic = all_continuous() ~ "{mean} ({sd})",
    include = c(ivs, dvs)) |>
  modify_caption("Table 1. Descriptive statistics of data.")
table1

```

## Mutual Information and Conditional Mutual Information

As mentioned in the Feature Selection section of the Methods section in this paper, the objective, quantitative measures of both mutual information (MI) and conditional mutual information (CMI). Figures 2.1 and 2.2 indicate the corresponding heatmaps for MI and CMI, respectively.

```{r mi}
#| results: asis
#| cache: true
#| warning: false
#| echo: true

nbins <- sqrt(NROW(data))

numeric_cols <- c(ivs, dvs, 'Lat') # Columns to discretize
discretized_data <- data

for (col in numeric_cols) {
  discretized_data[[col]] <- discretize(discretized_data[[col]], disc = "equalwidth", nbins = nbins)
}

cor_matrix <- cor(discretized_data[numeric_cols], use = "complete.obs")

# Print correlation matrix to understand relationships
# print(cor_matrix)

for (dv in dvs) {
  for (iv in ivs) {
  cond_info <- condinformation(discretized_data[[iv]], discretized_data[[dv]], discretized_data[['State']])
  # print(paste("Conditional Information for", iv, "and", dv, ":", cond_info))
  }
}
cmi_values <- matrix(0, nrow = length(ivs), ncol = length(dvs))
rownames(cmi_values) <- ivs
colnames(cmi_values) <- dvs

mi_values <- matrix(0, nrow = length(ivs), ncol = length(dvs))
rownames(mi_values) <- ivs
colnames(mi_values) <- dvs

for (i in 1:length(ivs)) {
  for (j in 1:length(dvs)) {
    mi_values[i, j] <- condinformation(discretized_data[[ivs[i]]], 
                                        discretized_data[[dvs[j]]])
  }
}

# Melt the matrix for ggplot
mi_melted <- melt(mi_values)
colnames(mi_melted) <- c("IV", "DV", "MI")

# Create the heatmap
ggplot(mi_melted, aes(x = DV, y = IV, fill = MI)) +
  geom_tile() +
  geom_text(aes(label = round(MI, 3)), family = "Baskerville") + 
  scale_fill_gradient(low = "white", high = "red") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        text = element_text(family = "Baskerville", size = 14),
        plot.title = element_text(hjust = 0.5, family = "Baskerville"),
        plot.caption = element_text(hjust = 0.5)) +
  labs(title = "Mutual Information (MI) Heatmap",
       x = "Health Conditions",
       y = "Environmental Factors",
       fill = "MI",
       caption = "Figure 2.1 — Heatmap of Mutual Information Values")
```

```{r cmi}
#| results: asis
#| cache: true
#| warning: false
#| echo: true

nbins <- sqrt(NROW(data))

numeric_cols <- c(ivs, dvs, 'Lat') # Columns to discretize
discretized_data <- data

for (col in numeric_cols) {
  discretized_data[[col]] <- discretize(discretized_data[[col]], disc = "equalwidth", nbins = nbins)
}

cor_matrix <- cor(discretized_data[numeric_cols], use = "complete.obs")

# Print correlation matrix to understand relationships
# print(cor_matrix)

for (dv in dvs) {
  for (iv in ivs) {
  cond_info <- condinformation(discretized_data[[iv]], discretized_data[[dv]], discretized_data[['State']])
  # print(paste("Conditional Information for", iv, "and", dv, ":", cond_info))
  }
}
cmi_values <- matrix(0, nrow = length(ivs), ncol = length(dvs))
rownames(cmi_values) <- ivs
colnames(cmi_values) <- dvs

for (i in 1:length(ivs)) {
  for (j in 1:length(dvs)) {
    cmi_values[i, j] <- condinformation(discretized_data[[ivs[i]]], 
                                        discretized_data[[dvs[j]]], 
                                        discretized_data[['State']])
  }
}

# Melt the matrix for ggplot
cmi_melted <- melt(cmi_values)
colnames(cmi_melted) <- c("IV", "DV", "CMI")

# Create the heatmap
ggplot(cmi_melted, aes(x = DV, y = IV, fill = CMI)) +
  geom_tile() +
  geom_text(aes(label = round(CMI, 3)), family = "Baskerville") + 
  scale_fill_gradient(low = "white", high = "red") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        text = element_text(family = "Baskerville", size = 14),
        plot.title = element_text(hjust = 0.5, family = "Baskerville"),
        plot.caption = element_text(hjust = 0.5)) +
  labs(title = "Conditional Mutual Information (CMI) Heatmap",
       x = "Health Conditions",
       y = "Environmental Factors",
       fill = "CMI",
       caption = "Figure 2.2 — Heatmap of Conditional Mutual Information Values")

```

## Models

```{r analysis code}
#| results: asis
#| cache: true
#| warning: false
#| echo: true
#| eval: false

for (dv in dvs) {
    cat("\n## ", dv, "\n\n")
    
    cat("### Model Fitting\n\n")
    
    rds_file <- paste0("fsmodel_", dv, ".rds")
    if (!file.exists(rds_file)) {
      cat(paste("RDS file", rds_file, "not found.\n\n"))
      next
    }
    
    modG <- readRDS(file = rds_file)
    #plot(modG, residuals = TRUE)
    
    # TRIAL STUFF

    pred_grid <- expand.grid(
      ht_ami = seq(min(data$ht_ami), max(data$ht_ami), length.out = 100),
      nsaverage = mean(data$nsaverage),
      est_vmiles = mean(data$est_vmiles),
      est_ptrp = mean(data$est_ptrp),
      State = unique(data$State)
    )

    # Make predictions
    preds <- predict(modG, newdata = pred_grid, se.fit = TRUE, type = "terms")

    # Create a data frame for plotting
    plot_data <- data.frame(
      ht_ami = rep(pred_grid$ht_ami, times = length(unique(data$State))),
      State = rep(unique(data$State), each = 100),
      Effect = preds$fit[, "s(ht_ami,nsaverage,State)"],
      SE = preds$se.fit[, "s(ht_ami,nsaverage,State)"]
    )

    # Create the plot
    testplot <- ggplot(plot_data, aes(x = ht_ami, y = Effect, color = State)) +
      geom_line() +
      # geom_ribbon(aes(ymin = Effect - 1.96 * SE, 
      #                 ymax = Effect + 1.96 * SE, 
      #                 fill = State), 
      #             alpha = 0.2) +
      labs(x = "ht_ami", y = "Effect", 
          title = "Smooth effect of ht_ami by State") +
      theme_minimal()

    print(testplot)

    
    cat("\n\n### Model Summary\n\n")
    sum_modG <- summary(modG)
    sum_modG_text <- capture.output(print(sum_modG))
    cat("```\n")
    cat(paste(sum_modG_text, collapse = "\n"))
    cat("\n```\n\n")


    ivlist <- list("est_vmiles", "est_ptrp", "ht_ami", "nsaverage")
    

    cat("\n### Odds Ratios \n\n")

    format_or_gam <- function(or_data, digits = 3, html = TRUE) {
      # Round numeric columns
      or_data[] <- lapply(or_data, function(x) if(is.numeric(x)) round(x, digits) else x)

      
        kable(or_data, 
              format = "html",
              digits = digits,
              align = c('l', 'r', 'r', 'r', 'r')) %>%
          kable_styling(bootstrap_options = c("striped", "hover"),
                      full_width = FALSE,
                      position = "left") %>%
          row_spec(0, bold = TRUE) 
          write.csv(or_data, paste0("/Users/dmach/Downloads/OR_", dv, ".csv"))
      }
    
    for (iv in ivlist) {
      or <- or_gam(
        data = data,
        model = modG,
        pred = iv,
        percentage = 20,
        slice = TRUE 
      )
      f <- format_or_gam(or)
      print(f)
    }

    cat("\n\n")  # Add space between analyses
}
```

::: panel-tabset
```{r analysis}
#| results: asis
#| cache: true
#| warning: false
#| echo: true

dv_data <- data[, dvs]

counter <- 1
for (dv in dvs) {
    cat("\n## ", dv, "\n\n")
    
    cat("### Model Fitting\n\n")
    
    rds_file <- paste0("fsmodel_", dv, ".rds")
    if (!file.exists(rds_file)) {
      cat(paste("RDS file", rds_file, "not found.\n\n"))
      next
    }
    
    modG <- readRDS(file = rds_file)
    plot(modG, residuals = TRUE, shade = TRUE, shade.col = "lightblue")
    
    cat("\n\n### Model Predictions\n\n")
    prediction_data <- with(data, data.frame(
      dv_value = dv_data[, counter],
      est_vmiles = est_vmiles,
      est_ptrp = est_ptrp,
      ht_ami = ht_ami,
      nsaverage = nsaverage,
      State = State 
    ))
    
    # link scale prediction
    predictions <- predict.gam(modG, newdata = prediction_data, type = "link", se.fit = TRUE)
    
    predictions_df <- as.data.frame(predictions)
    
    # plogis (return to 0-1 probs scale)
    prediction_data$prediction <- plogis(predictions_df$fit)
    
    prediction_data$residual <- prediction_data$prediction - prediction_data[[1]]
    
    residual_plot <- ggplot(data = prediction_data, aes(x = prediction, y = residual)) + 
      geom_point(alpha = 0.5) +
      geom_hline(yintercept = 0, linetype = "dashed", color = "lightblue") +
      theme_minimal() +
      labs(x = "Predicted Values", y = "Residuals")
    
    print(residual_plot)
    

    
    cat("\n\n### Model Summary\n\n")
    sum_modG <- summary(modG)
    
    parametric_table <- as.data.frame(summary(modG)$p.table)
    
    print(
      knitr::kable(parametric_table, format = "html") |>
        kable_styling("striped")
      )
    
    smooth_table <- as.data.frame(summary(modG)$s.table)
    
    print(
      knitr::kable(smooth_table, format = "html") |>
        kable_styling("striped")
      )


    ivlist <- list("est_vmiles", "est_ptrp", "ht_ami", "nsaverage")
    

    # cat("\n### Odds Ratios \n\n")

    # format_or_gam <- function(or_data, digits = 3, html = TRUE) {
    #   # Round numeric columns
    #   or_data[] <- lapply(or_data, function(x) if(is.numeric(x)) round(x, digits) else x)
    # 
    #   
    #     kable(or_data, 
    #           format = "html",
    #           digits = digits,
    #           align = c('l', 'r', 'r', 'r', 'r')) %>%
    #       kable_styling(bootstrap_options = c("striped", "hover"),
    #                   full_width = FALSE,
    #                   position = "left") %>%
    #       row_spec(0, bold = TRUE) 
    #       write.csv(or_data, paste0("/Users/dmach/Downloads/OR_", dv, ".csv"))
    #   }
    # 
    # for (iv in ivlist) {
    #   or <- or_gam(
    #     data = data,
    #     model = modG,
    #     pred = iv,
    #     percentage = 20,
    #     slice = TRUE 
    #   )
    #   f <- format_or_gam(or)
    #   print(f)
    # }

    cat("\n\n")  # Add space between analyses
    
    counter <- counter + 1
}
```
:::

Tables 2.1-2.7 display the parameter estimates for the hierarchical generalised additive models. used in this analysis. Since there were multiple dependent variables analysed in this analysis, there are multiple tables to account for each dependent variable. The variables shown reflect the parsimonious feature selection process introduced in the Methods section of this paper.

### Model Parameters

::: panel-tabset
```{r extrastats table}
#| results: asis
#| warning: false
#| cache: true
#| echo: true

counter <- 1

for (dv in dvs) {
    cat("\n## ", dv, "\n\n")

    rds_file <- paste0("fsmodel_", dv, ".rds")
    if (!file.exists(rds_file)) {
      cat(paste("RDS file", rds_file, "not found.\n\n"))
      next
    }

    modG <- readRDS(file = rds_file)
    
    options(scipen = 100, digits = 4)
    
    stats_df <- data.frame(
      Statistics = c("R-squared (adj)", "Deviance explained", "Number of observations", 
                "FREML score", "Scale estimate"),
      Value = c(round(summary(modG)$r.sq, 3), 
                round(summary(modG)$dev.expl, 3), 
                formatC(summary(modG)$n, format = "f", digits = 0), 
                formatC(summary(modG)$sp.criterion, format = "f", digits = 0), 
                round(summary(modG)$scale, 7))
    )
    
    print(
      knitr::kable(stats_df, format = "html", caption = paste0("Table 2.", counter, " — Parameter estimates of HGAM for ", dv)) |>
        kable_styling("striped")
      ) 
    
    counter <- counter + 1
    
}

```
:::

### Concurvity

Tables 3.1(1-3) to 3.7(1-3) display the concurvity estimates for the same models summarised in Tables 2.1 to 2.7, while Figures 3.1(1-3) to 3.7(1-3) present the numerical values shown in tables 3.1 to 3.7 in heatmap form.

```{r concurvity code}
#| results: asis
#| warning: false
#| echo: true
#| eval: false

for (dv in dvs) {
    cat("\n## ", dv, "\n\n")

    rds_file <- paste0("fsmodel_", dv, ".rds")
    if (!file.exists(rds_file)) {
      cat(paste("RDS file", rds_file, "not found.\n\n"))
      next
    }

    modG <- readRDS(file = rds_file)
    
    # save / load the concurvity files as RDS 

    # cv <- concurvity(modG, full = FALSE)
    # saveRDS(cv, file = paste("concurvity_", dv))
    
    rdsConc <- paste("concurvity_", dv)
    if (!file.exists(rdsConc)) {
      cat(paste("Concurvity data file", rdsConc, "not found.\n\n"))
      next
    }
    
    cv <- readRDS(file = rdsConc)
    tablefunct <- function(listMatrix, index) {
      # assign proper type
      if (index == 1) {
        type <- " — Worst"
      }
      else if (index == 2) {
        type <- " — Observed"
      }
      else {
        type <- " — Estimate"
      }
      
      # now, print the output
      cat(paste("### Concurvity", type, " \n\n"))
      print(
      knitr::kable(listMatrix, format = "html") |>
        kable_styling("striped")
      )
    }
    
    # make 3 separate tables: worst, observed, estimate (in order) 
    i <- 1
    while (i <= 3) {
      tablefunct(cv[[i]], i)
      i <- i + 1
    }

    
}

```

::: panel-tabset
```{r concurvity}
#| results: asis
#| warning: false
#| echo: true
#| cache: true

counter <- 1

for (dv in dvs) {
    cat("\n## ", dv, "\n\n")

    rds_file <- paste0("fsmodel_", dv, ".rds")
    if (!file.exists(rds_file)) {
      cat(paste("RDS file", rds_file, "not found.\n\n"))
      next
    }

    modG <- readRDS(file = rds_file)
    
    # save / load the concurvity files as RDS 

    # cv <- concurvity(modG, full = FALSE)
    # saveRDS(cv, file = paste("concurvity_", dv))
    
    rdsConc <- paste("concurvity_", dv)
    if (!file.exists(rdsConc)) {
      cat(paste("Concurvity data file", rdsConc, "not found.\n\n"))
      next
    }
    
    cv <- readRDS(file = rdsConc)
    tablefunct <- function(listMatrix, index) {
      # first, assign proper headings
      if (index == 1) {
        type <- " — Worst"
        caption <- paste0("Table 3.", counter, index, " — Maximum ||g||/||f|| Values for HGAM of ", dv)
        figure <- paste0("Figure 3.", counter, index, " — Heatmap for Maximum ||g||/||f|| Values for HGAM of ", dv)
      }
      else if (index == 2) {
        type <- " — Observed"
        caption <- paste0("Table 3.", counter, index, " — Observed ||g||/||f|| Values for HGAM of ", dv)
        figure <- paste0("Figure 3.", counter, index, " — Heatmap for Observed ||g||/||f|| Values for HGAM of ", dv)
      }
      else {
        type <- " — Estimate"
        caption <- paste0("Table 3.", counter, index, " — Observed (F-norm for basis of g)/(F-norm for basis of f) Values for HGAM of ", dv)
        figure <- paste0("Figure 3.", counter, index, " — Heatmap for Observed (F-norm for basis of g)/(F-norm for basis of f) Values for HGAM of ", dv)
      }
      
      # now, print the output
      cat(paste("\n### Concurvity", type, " \n\n"))
      print(
      knitr::kable(listMatrix, format = "html", caption = caption) |>
        kable_styling("striped")
      )
      meltMatrix <- melt(listMatrix)
      
      hmap <- ggplot(data = meltMatrix,
               aes(x = Var1, y = reorder(Var2, desc(Var2)), fill = value)) + 
        geom_tile() + 
        geom_text(aes(label = round(value, 3)), family = "Baskerville") + 
        scale_fill_gradient(low = "royalblue1", high = "coral1") +  
        theme_minimal() +
        theme(text = element_text(family = "Baskerville", size = 14), 
              axis.text.x = element_text(angle = 45, hjust = 1),
              plot.caption = element_text(hjust = 0.5)) + 
        labs(caption = figure, x = "", y = "")
        print(hmap)
      invisible(cat("\n\n"))
    }
    
    # make 3 separate tables and heatmaps: worst, observed, estimate (in order) 
    i <- 1
    while (i <= 3) {
      tablefunct(cv[[i]], i)
      i <- i + 1
    }
    
    counter <- counter + 1
    
}

```
:::

## Quasibinomial Model Interpretation

Prevalence can be derived from the partial effects graphs of the GAMs shown in the Models section with the following formula:

```{r}
#| eval: false

prevalence = exp(linear_predictor) / (1 + exp(linear_predictor))
```
